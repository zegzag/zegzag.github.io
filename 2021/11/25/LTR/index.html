<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Learning to Rank,Ranking,Loss," />










<meta name="description" content="以下内容是依照 Microsoft Research Asia 的 Tie-Yan Liu 的一篇PPT Learning to Rank for Infomation to Retrieval，结合各个相关论文翻译归纳整理而来。 评估标准  NDCG (Normalized Discounted Cumulative Gain) NDCG at position n： 假设：">
<meta property="og:type" content="article">
<meta property="og:title" content="LTR">
<meta property="og:url" content="http://example.com/2021/11/25/LTR/index.html">
<meta property="og:site_name" content="泽">
<meta property="og:description" content="以下内容是依照 Microsoft Research Asia 的 Tie-Yan Liu 的一篇PPT Learning to Rank for Infomation to Retrieval，结合各个相关论文翻译归纳整理而来。 评估标准  NDCG (Normalized Discounted Cumulative Gain) NDCG at position n： 假设：">
<meta property="og:locale">
<meta property="article:published_time" content="2021-11-25T11:00:00.000Z">
<meta property="article:modified_time" content="2021-11-25T11:00:00.000Z">
<meta property="article:author" content="Z">
<meta property="article:tag" content="Learning to Rank">
<meta property="article:tag" content="Ranking">
<meta property="article:tag" content="Loss">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://example.com/2021/11/25/LTR/"/>





  <title>LTR | 泽</title>
  








<meta name="generator" content="Hexo 6.3.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">泽</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">君子藏器于身，待时而动</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/11/25/LTR/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泽">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">LTR</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-11-25T19:00:00+08:00">
                2021-11-25
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2021-11-25T19:00:00+08:00">
                2021-11-25
              </time>
            
          </span>

          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i> 阅读数
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>  以下内容是依照 Microsoft Research Asia 的 Tie-Yan Liu 的一篇PPT <a
target="_blank" rel="noopener" href="https://web.archive.org/web/20170808044438/http://wwwconference.org/www2009/pdf/T7A-LEARNING%20TO%20RANK%20TUTORIAL.pdf">Learning
to Rank for Infomation to
Retrieval</a>，结合各个相关论文翻译归纳整理而来。</p>
<h1 id="评估标准">评估标准</h1>
<ul>
<li><strong>NDCG (Normalized Discounted Cumulative Gain)</strong><br />
NDCG at position n： 假设：
<ul>
<li><p>有 <span class="math inline">\(n\)</span> 个 <code>doc</code>:
<span class="math inline">\(\{1,
...,n\}\)</span>，每个<code>doc</code>的<strong>标注相关性</strong>为
<span class="math inline">\(y_i\)</span>，<strong>预测相关性</strong>为
<span class="math inline">\(\hat{y}_i\)</span>，其中 <span
class="math inline">\(i\)</span> 指代 <code>doc</code>。</p></li>
<li><p><span class="math inline">\(\pi\)</span> 为一种排列方式，在 <span
class="math inline">\(\pi\)</span>
的排列方式下，<code>doc</code>的排序结果为：<span
class="math inline">\([\pi(1), ..., \pi(n)]\)</span>，对应的分数排序为
<span class="math inline">\([s_{\pi(1)}, ...,
s_{\pi(n)}]，\)</span><span class="math inline">\(\pi^*\)</span>
为最佳排列方式。可见，最佳排序方式为
<code>[1, ...,n].sort(key = lambda x: s(x)</code>，即按照 <span
class="math inline">\(s\)</span> 去排序。则有： <span
class="math display">\[
  DCG@k(\pi) = \sum_{j=1}^k G(j;r) * D(j)\\
  G(j;r) = 2^{s_{\pi(j)} - 1},\ D(j) = log(j+1)\\
  NDCG@k(\pi) = \frac{DCG@k(\pi)}{DCG@k(\pi^*)}
\]</span> 其中 <span class="math inline">\(j\)</span> 表示
<code>Position</code>，<span class="math inline">\(G\)</span> 表示
<code>Gain</code>，<span class="math inline">\(D\)</span> 表示
<code>Position Discount</code>，则 <span
class="math inline">\(\sum\)</span> 表示
<code>Cumulating</code>。</p></li>
<li><p>一般的实现为<code>ndcg = dcg(y_pred, y_true)/dcg(y_true, y_true)</code>，其中
<code>y_pred</code> 为模型预测值，<code>y_true</code>
为真实的<code>label</code>。在<code>dcg()</code>里，将<code>y_true</code>
按照 <code>y_pred</code> 进行排序。</p>
<ul>
<li>衍生出的问题是：如果有两个<code>y_pred</code>
<strong>一样</strong>该怎么办呢？一样意味着相同分数下的 <code>doc</code>
可以有多种排序情况。
<ul>
<li>计算相同 <code>y_pred</code> 下的 <span
class="math inline">\(G\)</span> 均值和 <span
class="math inline">\(D\)</span> 均值，再求和。</li>
</ul></li>
<li>具体的实现可以参看 <code>sklearn.metrics.ndcg_score</code> 源码。
<ul>
<li>注意<code>sklearn</code> 源码中有一个 <code>ignore_ties</code>
选项，指的是如果 <code>y_pred</code>
存在相同的值，那么这些相同的值被视为一个 <code>tie</code>。此时在计算
<code>dcg</code>的时候会有一些区别，具体可见源码。</li>
<li><code>sklearn</code>当中的<code>Gain</code>的映射直接放在<code>y_true</code>里面。</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>MAP (Mean Average Precision)</strong> <span
class="math display">\[
      \begin{aligned}
          &amp;P@n=\frac{NumRelDoc(n)}{n}\\
          &amp;AP@n=\frac{\sum_k P@k \cdot
IsRelevant(doc_k)}{NumRelDoc(n)}\\
          &amp;MAP=\frac{\sum_{q=1}^QAP_q}{Q}
      \end{aligned}
  \]</span>
<ul>
<li>其中 <span class="math inline">\(NumRelDoc(n)\)</span> 表示前 <span
class="math inline">\(n\)</span> 位相关 doc 的数量。<span
class="math inline">\(IsRelevant(doc)\)</span> 表示该 <span
class="math inline">\(doc\)</span> 是否相关，为 0-1 函数。</li>
<li><span class="math inline">\(AP_q\)</span> 表示针对 <span
class="math inline">\(query = q\)</span> 的平均准确率</li>
</ul></li>
</ul>
<h1 id="machine-learning-model">Machine Learning Model</h1>
<p>  作者基于机器学习模型的建模方式按照
<code>Pointwise, Pairwise, Listwise</code> 对 LTR
领域的模型进行了分类。</p>
<ul>
<li>Pointwise:
<ul>
<li>Input: single document</li>
<li>Output: scores or class lables</li>
</ul></li>
<li>Pairwise:
<ul>
<li>Input: document pairs</li>
<li>Output: partial order preference</li>
</ul></li>
<li>Listwise:
<ul>
<li>Input: document collections</li>
<li>Output: ranked document list</li>
</ul></li>
</ul>
<h2 id="pointwise-approach">Pointwise Approach</h2>
<p>   Pointwise 方法将 Rank
任务降低为<strong>针对单个文档</strong>的<strong>回归</strong>或<strong>分类</strong>任务。</p>
<ul>
<li><a
target="_blank" rel="noopener" href="https://ciir.cs.umass.edu/pubfiles/ir-339.pdf">Discriminative
Models for Information Retrieval</a></li>
<li><a
target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper/2007/file/b86e8d03fe992d1b0e19656875ee557c-Paper.pdf">McRank:
Learning to Rank Using Multiple Classification and Gradient
Boosting</a></li>
</ul>
<p>   Pointwise
中的作为分类任务的<strong>分类标签</strong>是独立于query的，这是个很不合理的假设。</p>
<p>   Pairwise方法仍没有直接建模整个排序结果，pair对
的偏序关系和整个的排序结果如何对应起来仍是不清楚的。</p>
<h2 id="listwise-approach">Listwise Approach</h2>
<h3 id="直接优化-ir-的评估度量">直接优化 IR 的评估度量</h3>
<p>   像 NDCG
这样的评估标准是基于整个排序结果，所以它是非平滑且不可导的。这就使得基于该标准的优化算法非常困难。解决办法：</p>
<ul>
<li>嵌入：AdaRank</li>
<li>优化其一个光滑且可导的上界：SVM-MAP
<ul>
<li>上界是否足够紧？</li>
</ul></li>
<li>软化或近似评估度量，使其光滑且可导：SoftRank
<ul>
<li>SoftNDCG是否真的能很好地近似NDCG ？</li>
</ul></li>
<li>直接改进优化算法，来优化非平滑非可导的评估度量：
<ul>
<li>RankGP</li>
<li>LambdaRank</li>
</ul></li>
</ul>
<h3 id="定义-listwise-的损失函数">定义 Listwise 的损失函数</h3>
<ul>
<li><strong>Loss in Listwise Approach</strong>
<ul>
<li>Listwise 的 Rank 任务整体可以进行如下定义：令 <span
class="math inline">\(X\)</span>
为输入空间，表示一组待排序的对象(特征)集合。 <span
class="math inline">\(Y\)</span>
为输出空间，表示该集合的一个（最优）排列组合。<span
class="math inline">\(P_{XY}\)</span> 表示 <span
class="math inline">\(X\times Y\)</span> 上的联合概率分布。<span
class="math inline">\(h:X\rightarrow Y\)</span> 表示 ranking 函数，<span
class="math inline">\(H\)</span> 表示 <span
class="math inline">\(h\)</span> 所属的函数空间，即 <span
class="math inline">\(h\in H\)</span>，那么期望损失如下： <span
class="math display">\[
  \begin{aligned}
    R(\mathbf{h})=\int_{X\times Y}L(\mathbf{h}(\mathbf{x}),
\mathbf{y})dP(\mathbf{x}, \mathbf{y})
  \end{aligned}
\]</span> 其中 <code>true loss</code> 为如下定义： <span
class="math display">\[
  L_{true}(\mathbf{h}(\mathbf{x}), \mathbf{y})=\begin{cases}
              1,\ \text{if}\ \mathbf{h}(\mathbf{x})\neq \mathbf{y}\\
              0,\ \text{if}\ \mathbf{h}(\mathbf{x})=\mathbf{y}
          \end{cases}
\]</span></li>
<li>如果把 <span class="math inline">\(X\)</span>
中的样本都看做独立同分布的，则有经验损失(Emperical Loss)： <span
class="math display">\[
  R_S(g)=\frac{1}{m}\sum_{i=1}^mL(\mathbf{h}(\mathbf{x}^{(i)}),
\mathbf{y}^{(i)})
\]</span>
<ul>
<li>其中 <span class="math inline">\(\cdot^{(i)}\)</span> 表示从属于第
<span class="math inline">\(i\)</span> 个 <code>query</code>。</li>
<li><span class="math inline">\(\mathbf{y}^{(i)} =
(y_1^{(i)},...,y_{n_i}^{(i)})\)</span>； <span
class="math inline">\(y_j^{(i)}\)</span> 表示第 <span
class="math inline">\(j\)</span> 位置上的文档 <span
class="math inline">\(d_j^{(i)}\)</span> 的 <code>groundtruth</code>
分数。</li>
<li><span class="math inline">\(\mathbf{x}^{(i)} =
(\mathbf{x}_1^{(i)},...,\mathbf{x}_{n_i}^{(i)})\)</span>；<span
class="math inline">\(\mathbf{x}_j^{(i)}\)</span>，表示第 <span
class="math inline">\(j\)</span> 个位置上根据<code>doc</code> <span
class="math inline">\(d_j\)</span> 和 <code>query</code> <span
class="math inline">\(q_{(i)}\)</span> 提取的特征向量。可以看到，这里的
<span class="math inline">\(\mathbf{x}^{(i)}\)</span> 是个矩阵。在
<code>pairwise</code> 模型里，样本是从 <span
class="math inline">\(\mathbf{x}^{(i)}\)</span> 里面去抽取的，即抽取
<span class="math inline">\(\mathbf{x}_j^{(i)}, \mathbf{x}_k^{(i)},
\text{where}\ j\neq k\)</span> 组成pair对，然后如果 <span
class="math inline">\(y_j^{(i)}&gt; y_k^{(i)}\)</span>，则标签置为 <span
class="math inline">\(+1\)</span>，反之则置为 <span
class="math inline">\(-1\)</span>。</li>
<li><span class="math inline">\(\mathbf{h}\)</span> 进行加粗表示函数
<span class="math inline">\(\mathbf{h}\)</span> 输出的是个向量。</li>
</ul></li>
<li>注意到一般的 rank
过程都是先给每个对象打分，然后再根据该分数进行排序，则 <span
class="math inline">\(\mathbf{h}\)</span> 可以表示为： <span
class="math display">\[
  \mathbf{h}(\mathbf{x}^{(i)})=sort(g(x_1^{(i)}),...,g(x_{n_i}^{(i)}))
\]</span></li>
<li><code>true loss</code>损失函数的问题：
<ul>
<li>由于 <span class="math inline">\(L_{true}\)</span> 为 0-1 函数，且
<span class="math inline">\(R_S(g)\)</span> 中带有 <span
class="math inline">\(sort\)</span> 过程，所以 <span
class="math inline">\(R_S(g)\)</span> 是不可导的。</li>
</ul></li>
<li>代理损失(Surrogate Loss):<br />
   关于代理损失函数可以参考：<a
target="_blank" rel="noopener" href="https://stats.stackexchange.com/questions/263712/what-is-a-surrogate-loss-function">What
is a surrogate loss function?</a>，<a
target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/70387818">损失函数</a>。 <span
class="math display">\[
      R_S^{\phi}(g)=\frac{1}{m}\sum_{i=1}^m\phi (g(\mathbf{x}^{(i)}),
\mathbf{y}^{(i)})
  \]</span>
<ul>
<li>由大数定理可知： <span class="math display">\[
  \begin{aligned}
    R^{\phi}(g) &amp; = E_{X,Y}[\phi(g(\mathbf{x}), \mathbf{y})]\\
                &amp; = E_{X}[\sum_{\mathbf{y}\in
Y}P(\mathbf{y}|\mathbf{x})\phi(g(\mathbf{x}), \mathbf{y})]
  \end{aligned}
\]</span></li>
</ul></li>
</ul></li>
<li><strong>Permutaion Probability Space (置换概率空间) (Luce
Model)</strong><br />
  
假如我们要从概率论的角度，通过极大似然来最优化逼近最优排序，那么我们应该怎么来设计概率表达式呢？如果用
<span class="math inline">\(\mathbf{d}=\{1,...,n\}\)</span>
来标记待排序的全体对象，那么一次排列(<code>permutation</code>) <span
class="math inline">\(\pi\)</span>，则代表了一个 <span
class="math inline">\(\mathbf{d}\leftrightarrow\mathbf{d}\)</span>
的双射。<span class="math inline">\(\pi =\langle
\pi(1),...,\pi(n)\rangle\)</span>，<span
class="math inline">\(\pi(j)\)</span>表示位于位 <code>position</code>
<span class="math inline">\(j\)</span> 上的对象为 <span
class="math inline">\(\pi(j)\)</span>。<span
class="math inline">\(n\)</span> 个对象的全部可能的排列为 <span
class="math inline">\(\Omega_n\)</span>。那么概率公式 <span
class="math inline">\(P(\pi)\)</span> 该如何定义？<br />
   注意 <span class="math inline">\(\mathbf{d}=\{1,...,n\}\)</span>
里面的自然数指代对象，<span class="math inline">\(\pi(j)\)</span>
的自然数 <span class="math inline">\(j\)</span> 指代位置。 令 <span
class="math inline">\(\mathbf{s} = (s_1,...,s_n)\)</span>
表示由排序函数(<code>ranking function</code>)给出的 <span
class="math inline">\(n\)</span>
个对象的分数(这里的下标指代对象)。<br />
   <span class="math inline">\(P(\pi|\mathbf{s})\)</span>
必须具有如下特性，首先全部可能的排序概率和为1。其次，如果我们想用极大似然去优化，那么必定要保证，越接近最优排序的排序结果其概率越大，即得分高的更应该排在前面。由此引出
<strong>Luce Model: Permutaion Probability Space</strong>
<ul>
<li>定义：
<ul>
<li>假如 <span class="math inline">\(\pi\)</span> 是一个排列，<span
class="math inline">\(\mathbf{s}\)</span> 是给出的分数，<span
class="math inline">\(\phi(\cdot)\)</span>
是单调递增的函数。则在给定分数 <span
class="math inline">\(\mathbf{s}\)</span> 后，排列 <span
class="math inline">\(\pi\)</span> 的概率为： <span
class="math display">\[
  \begin{aligned}
    &amp; P(\pi|\mathbf{s}) = P_{\mathbf{s}}(\pi)
=\prod_{j=1}^n\frac{\phi(s_{\pi(j)})}{\sum_{k=j}^n\phi(s_{\pi(k)})}\\
  \end{aligned}
\]</span></li>
</ul></li>
<li>性质：
<ul>
<li>和为1： <span class="math display">\[
  \sum_{\pi\in\Omega_n}P_s(\pi) = 1
\]</span></li>
<li>保序：<br />
给定任意两个排序 <span
class="math inline">\(\pi,\pi&#39;\in\Omega_n\)</span>，若有：
<ol type="1">
<li><span class="math inline">\(\pi(p)=\pi&#39;(q),\pi(q)=\pi&#39;(p),
p&lt;q\)</span>;</li>
<li><span class="math inline">\(\pi(r)=\pi&#39;(r), r\neq
p,q\)</span>;</li>
<li><span class="math inline">\(s_{\pi(q)}&gt;s_{\pi(p)}\)</span>。则有
<span
class="math inline">\(P_{\mathbf{s}}(\pi)&gt;P_{\mathbf{s}}(\pi&#39;)\)</span></li>
</ol>
<ul>
<li>通俗的讲就是仅仅交换某一排序中的两个位置为 <span
class="math inline">\(p,q\)</span> 的对象，如果位置为 <span
class="math inline">\(p\)</span> 的对象的分数 <span
class="math inline">\(s_{\pi(p)}&gt;s_{\pi(p)}\)</span>，那么交换后概率降低。</li>
</ul></li>
</ul></li>
<li>由此定义我们可以给出基于KL散度的概率损失函数为： <span
class="math display">\[
  \begin{aligned}
    L(\mathbf{h}(\mathbf{x}),\mathbf{y}) &amp; =
-\sum_{\pi\in\Omega_n}P_{\mathbf{y}}(\pi)logP_{\mathbf{h}}(\pi)\\
    &amp;
=-\sum_{\pi\in\Omega_n}P(\pi|\mathbf{y})logP(\pi|\mathbf{x};\mathbf{h})
  \end{aligned}
\]</span>
<ul>
<li>然后就可以用一般的梯度下降法去优化了，但是这里的 <span
class="math inline">\(\sum\)</span> 的数量级别是 <span
class="math inline">\(n!\)</span>，没法计算。</li>
</ul></li>
</ul></li>
<li>一些 Surrogate Loss 例子：
<ul>
<li><a
target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2007-40.pdf">ListNet</a>:<br />
针对前面 Permutaion Probability Space
定义下损失函数计算量过大的问题，ListNet 提出了一个简化版本 Top One
Probability： <span class="math display">\[
  \begin{aligned}
    P_{\mathbf{s}}(j) &amp;= \sum_{\pi(1) =
j,\pi\in\Omega_n}P_{\mathbf{s}}(\pi)\\
    &amp;=\frac{\phi(s_j)}{\sum_{k=1}^n\phi(s_k)}
  \end{aligned}
\]</span>
<ul>
<li>即 <span class="math inline">\(P_{\mathbf{s}}(j)\)</span>
为首位为对象 <span class="math inline">\(j\)</span>
的全体排序的概率和。公式论文里有推导。</li>
<li>Top One Probability 也具有保序性质，即若 <span
class="math inline">\(s_j&gt;s_k\)</span>，则有 <span
class="math inline">\(P_{\mathbf{s}}(j)&gt;P_{\mathbf{s}}(k)\)</span></li>
<li>于是有损失函数： <span class="math display">\[
  L(\mathbf{h}(\mathbf{x}), \mathbf{y}) =
-\sum_{j=1}^nP_{\mathbf{y}}(j)logP_{\mathbf{h}}(j)
\]</span>
<ul>
<li>一般为了求导方便取 <span class="math inline">\(\phi =
\text{exp}\)</span></li>
</ul></li>
</ul></li>
<li><a target="_blank" rel="noopener" href="http://icml2008.cs.helsinki.fi/papers/167.pdf">ListMLE</a>:
<ul>
<li>Likelihood Loss (似然损失)：<br />
  既然已经有了 <span class="math inline">\(P(\pi|\mathbf{y})\)</span> 和
<span
class="math inline">\(P(\pi|\mathbf{x};\mathbf{h})\)</span>，为何不直接优化最优排序(按照
<span class="math inline">\(\mathbf{y}\)</span>
进行排序)的似然(<code>likelihood</code>)呢 ？ <span
class="math display">\[
  L(g(\mathbf{x}), \mathbf{y}) = -log
P(\pi_{\mathbf{y}}|\mathbf{x};\mathbf{h})\\
  P(\pi_{\mathbf{y}}|\mathbf{x};\mathbf{h}) =
\prod_{i=1}^n\frac{\text{exp}(g(x_{y(i)}))}{\sum_{k = i}^n
\text{exp}(g(x_{y(k)}))}
\]</span></li>
</ul></li>
<li><a
target="_blank" rel="noopener" href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.159.5316&amp;rep=rep1&amp;type=pdf">RankCosine</a>:
<ul>
<li>Cosine Loss (余弦损失)： <span class="math display">\[
  \phi(g(\mathbf{x}), \mathbf{y}) =
\frac{1}{2}(1-\frac{\psi^T_{\mathbf{y}}(\mathbf{x})g(\mathbf{x})}{||\psi_{\mathbf{y}}(\mathbf{x})||||g(\mathbf{x})||})
\]</span>
<ul>
<li><span class="math inline">\(\psi_{\mathbf{y}}\)</span>
是标签函数映射下得到的每个 <code>doc</code> 的分数</li>
<li>这里不涉及排序，即按默认 <span class="math inline">\(n\)</span>
个文档 <span class="math inline">\(\text{doc} = \{1,...,n\}\)</span>
对齐后计算两个函数 <span
class="math inline">\(\psi_{\mathbf{y}}(\mathbf{x})\)</span> 和 <span
class="math inline">\(g(\mathbf{x})\)</span> 的余弦相似度。</li>
</ul></li>
</ul></li>
<li>在我们把精力都放在 Surrogate Loss
上时，不要忘记了模型最终学出的结果是啥，模型最终还是会学出一个映射 <span
class="math inline">\(h\)</span>，然后对每个样本 <span
class="math inline">\(\mathbf{x}\)</span> 算一个分<code>Score</code>
<span class="math inline">\(s =
h(\mathbf{x})\)</span>，只是这个<code>Score</code>会有如下性质：<strong>根据该<code>score</code>进行排序得到最优排序的概率最大(即为最优排序)</strong></li>
</ul></li>
</ul>
<h2 id="pairwise-approach">Pairwise Approach</h2>
<p>   Pairwise 方法将 Rank 任务降低为基于某个query的 <strong>doc
pair对</strong> 的<strong>分类任务</strong></p>
<ul>
<li><a
target="_blank" rel="noopener" href="https://icml.cc/Conferences/2015/wp-content/uploads/2015/06/icml_ranking.pdf">RankNet:
Learning to Rank using Gradient Descent</a></li>
<li><a
target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2006-155.pdf">FRank:
A Ranking Method with Fidelity Loss</a></li>
<li><a
target="_blank" rel="noopener" href="https://www.jmlr.org/papers/volume4/freund03a/freund03a.pdf">RankBoost:
An Efficient Boosting Algorithm for Combining Preferences</a></li>
<li><a
target="_blank" rel="noopener" href="http://www.bigdatalab.ac.cn/~junxu/publications/SIGIR2006_AdaptSVM.pdf">IR
SVM: Adapting Ranking SVM to Document Retrieval</a><br />
   排序任务应该考虑两个重要而基本的问题：
<ul>
<li>越排在前面的结果越重要。</li>
<li>相关的文档数量必须针对不同的 <code>query</code> 是不同的。</li>
</ul>
   我们接着 Listwise Approach 的模型定义：<span
class="math inline">\(\mathbf{x}^{(i)} =
(\mathbf{x}_1^{(i)},...,\mathbf{x}_{n_i}^{(i)})\)</span>。假定 <span
class="math inline">\(g\)</span> 是一个线性函数，即 <span
class="math inline">\(g = \langle \mathbf{w},
\mathbf{x}\rangle\)</span>，如果 <span
class="math inline">\(s_j&gt;s_k\)</span>，则应该有 <span
class="math inline">\(g(\mathbf{x}_j)&gt;g(\mathbf{x}_k)\)</span>，即<span
class="math inline">\(\langle \mathbf{w},
\mathbf{x}_j-\mathbf{x}_k\rangle &gt; 0\)</span>。基于 <span
class="math inline">\(S = \{(\mathbf{x}_j,y_j)\}\)</span> 构造新的空间：
<span class="math display">\[
  \begin{aligned}
    S&#39;&amp;=\{(\mathbf{x}_j-\mathbf{x}_k, z_{jk})\}\\
    z_{jk}&amp; = \begin{cases}
      1, y_j&gt;y_k\\
      -1, y_j\leq y_k
    \end{cases}
  \end{aligned}
\]</span> 基于 <span class="math inline">\(S&#39;\)</span>
可以用支持向量机(SVM)来学习函数 <span class="math inline">\(g\)</span>
的权重 <span class="math inline">\(\mathbf{w}\)</span>。</li>
<li>Ref:
<ul>
<li><a
target="_blank" rel="noopener" href="https://stats.stackexchange.com/questions/263712/what-is-a-surrogate-loss-function">What
is a surrogate loss function?</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/70387818">损失函数</a></li>
</ul></li>
</ul>
<h1 id="implementation">Implementation</h1>
<ul>
<li>工程实现上目前业界开源的有：
<ul>
<li>tensorflow生态：<a
target="_blank" rel="noopener" href="https://www.tensorflow.org/ranking"><code>tf-ranking</code></a>
<ul>
<li>tf-ranking 的 demo
里，NN模型结构只是简单的点乘，实践发现没法在keras里面支持灵活的自定义模型。原因在于对变长序列(<code>tf.RaggledTensor</code>)的处理上。如果要自定义网络结构，必须要写底层的
tensorflow 的 api。</li>
</ul></li>
<li>pytorch生态：<a
target="_blank" rel="noopener" href="https://github.com/allegro/allRank"><code>allRank</code></a></li>
</ul></li>
<li>看源码可以发现，由于<code>LTR</code>的 <code>listwise</code>
损失函数输入为<strong>变长</strong>张量，而两者的底层loss的最终实现都是对变长张量做<code>padding</code>，进而实现
<code>loss</code>
的计算以及梯度回传。明白了源码的实现方式后，即可以自己整合损失函数和模型结构。</li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Learning-to-Rank/" rel="tag"># Learning to Rank</a>
          
            <a href="/tags/Ranking/" rel="tag"># Ranking</a>
          
            <a href="/tags/Loss/" rel="tag"># Loss</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2021/11/01/C++/" rel="next" title="C++">
                <i class="fa fa-chevron-left"></i> C++
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2021/11/26/ML/" rel="prev" title="ML">
                ML <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives%7C%7Carchive">
              
                  <span class="site-state-item-count">27</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">41</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/zegzag" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AF%84%E4%BC%B0%E6%A0%87%E5%87%86"><span class="nav-number">1.</span> <span class="nav-text">评估标准</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#machine-learning-model"><span class="nav-number">2.</span> <span class="nav-text">Machine Learning Model</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#pointwise-approach"><span class="nav-number">2.1.</span> <span class="nav-text">Pointwise Approach</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#listwise-approach"><span class="nav-number">2.2.</span> <span class="nav-text">Listwise Approach</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%B4%E6%8E%A5%E4%BC%98%E5%8C%96-ir-%E7%9A%84%E8%AF%84%E4%BC%B0%E5%BA%A6%E9%87%8F"><span class="nav-number">2.2.1.</span> <span class="nav-text">直接优化 IR 的评估度量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89-listwise-%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">2.2.2.</span> <span class="nav-text">定义 Listwise 的损失函数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pairwise-approach"><span class="nav-number">2.3.</span> <span class="nav-text">Pairwise Approach</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#implementation"><span class="nav-number">3.</span> <span class="nav-text">Implementation</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Z</span>

  
</div>
<!--

  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>

-->


        
<div class="busuanzi-count">
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访客数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"live2d-widget-model-hibiki"},"display":{"position":"right","width":150,"height":330,"hOffset":50,"vOffset":0},"mobile":{"show":true,"scale":0.5},"react":{"opacity":0.7}});</script></body>
</html>
